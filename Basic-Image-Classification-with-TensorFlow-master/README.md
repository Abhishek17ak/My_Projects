# Basic Image Classification with TensorFlow

## Introduction
Welcome to my project on Basic Image Classification using TensorFlow and Keras! In this project, I delve into the world of neural networks to solve a classic machine learning problem: digit recognition from handwritten images. My goal was to build, train, and evaluate a neural network that could accurately identify digits based on their images. Through this exercise, I gained a deeper understanding of TensorFlow, Keras, and the fundamentals of neural networks.

## Glossary
- **TensorFlow**: An open-source platform for machine learning that helps in building and training robust ML models.
- **Keras**: A high-level API that runs on top of TensorFlow, designed for rapid experimentation and development of neural networks.
- **Neural Network**: A computing framework designed to mimic the human brain, learning from numerical data.
- **MNIST Dataset**: A dataset of handwritten digits that is extensively used for training and testing in the field of machine learning.
- **Matplotlib**: A comprehensive library for creating static, animated, and interactive visualizations in Python.
- **One Hot Encoding**: A representation method for categorical variables to be better understood by machine learning algorithms.
- **Dense Layer**: A layer in a neural network where each neuron receives input from all neurons in the previous layer.
- **Activation Function**: Functions that introduce non-linearity to the model, helping it learn complex patterns.
- **Loss Function**: Measures how well the model performs during training by comparing the model's predictions with the actual data.
- **Optimizer**: Algorithms or methods used to change the attributes of your neural network such as weights to minimize loss functions.

## Project Description
I embarked on this project to apply my theoretical knowledge of TensorFlow and Keras to a practical challenge—recognizing handwritten digits using the MNIST dataset. The process involved:
- Constructing a neural network architecture with several densely connected layers.
- Implementing ReLU and Softmax activation functions to handle non-linear data and classify inputs into multiple categories.
- Training the model using categorical cross-entropy as the loss function and stochastic gradient descent (SGD) as the optimizer.
- Evaluating the model’s performance on a test set to assess its accuracy.

This project was not just about achieving high accuracy but also about understanding the underlying processes and decision-making involved in building effective neural network models.

