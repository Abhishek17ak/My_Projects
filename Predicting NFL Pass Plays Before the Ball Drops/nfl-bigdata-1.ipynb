{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84175,"databundleVersionId":9816926,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-16T20:15:37.852084Z","iopub.execute_input":"2024-10-16T20:15:37.852538Z","iopub.status.idle":"2024-10-16T20:15:37.870255Z","shell.execute_reply.started":"2024-10-16T20:15:37.852489Z","shell.execute_reply":"2024-10-16T20:15:37.868697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# For data processing and analysis\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set up plotting style\nplt.style.use('seaborn')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T20:15:37.872702Z","iopub.execute_input":"2024-10-16T20:15:37.873355Z","iopub.status.idle":"2024-10-16T20:15:39.302528Z","shell.execute_reply.started":"2024-10-16T20:15:37.873289Z","shell.execute_reply":"2024-10-16T20:15:39.300861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load game data\ngames = pd.read_csv('../input/nfl-big-data-bowl-2025/games.csv')\n\n# Load play data\nplays = pd.read_csv('../input/nfl-big-data-bowl-2025/plays.csv')\n\n# Load player data\nplayers = pd.read_csv('../input/nfl-big-data-bowl-2025/players.csv')\n\n# Load player play data\nplayer_play = pd.read_csv('../input/nfl-big-data-bowl-2025/player_play.csv')\n\n# Load tracking data for week 1 (you can load more weeks as needed)\ntracking_week1 = pd.read_csv('../input/nfl-big-data-bowl-2025/tracking_week_1.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T20:15:39.304392Z","iopub.execute_input":"2024-10-16T20:15:39.305030Z","iopub.status.idle":"2024-10-16T20:16:11.975605Z","shell.execute_reply.started":"2024-10-16T20:15:39.304982Z","shell.execute_reply":"2024-10-16T20:16:11.974130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Games dataset shape:\", games.shape)\nprint(\"Plays dataset shape:\", plays.shape)\nprint(\"Players dataset shape:\", players.shape)\nprint(\"Player Play dataset shape:\", player_play.shape)\nprint(\"Tracking Week 1 dataset shape:\", tracking_week1.shape)\n\n# Display first few rows of each dataset\nprint(\"\\nGames dataset preview:\")\nprint(games.head())\n\nprint(\"\\nPlays dataset preview:\")\nprint(plays.head())\n\nprint(\"\\nPlayers dataset preview:\")\nprint(players.head())\n\nprint(\"\\nPlayer Play dataset preview:\")\nprint(player_play.head())\n\nprint(\"\\nTracking Week 1 dataset preview:\")\nprint(tracking_week1.head())","metadata":{"execution":{"iopub.status.busy":"2024-10-16T20:16:11.979061Z","iopub.execute_input":"2024-10-16T20:16:11.979688Z","iopub.status.idle":"2024-10-16T20:16:12.031613Z","shell.execute_reply.started":"2024-10-16T20:16:11.979625Z","shell.execute_reply":"2024-10-16T20:16:12.030359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_missing_values(df, name):\n    missing = df.isnull().sum()\n    missing_percent = 100 * df.isnull().sum() / len(df)\n    missing_table = pd.concat([missing, missing_percent], axis=1, keys=['Missing Values', '% Missing'])\n    print(f\"\\nMissing values in {name} dataset:\")\n    print(missing_table[missing_table['Missing Values'] > 0])\n\ncheck_missing_values(games, 'Games')\ncheck_missing_values(plays, 'Plays')\ncheck_missing_values(players, 'Players')\ncheck_missing_values(player_play, 'Player Play')\ncheck_missing_values(tracking_week1, 'Tracking Week 1')","metadata":{"execution":{"iopub.status.busy":"2024-10-16T20:16:12.032983Z","iopub.execute_input":"2024-10-16T20:16:12.033434Z","iopub.status.idle":"2024-10-16T20:16:21.099294Z","shell.execute_reply.started":"2024-10-16T20:16:12.033387Z","shell.execute_reply":"2024-10-16T20:16:21.097935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Load the data\nplays = pd.read_csv('../input/nfl-big-data-bowl-2025/plays.csv')\ntracking_week1 = pd.read_csv('../input/nfl-big-data-bowl-2025/tracking_week_1.csv')\n\n# Merge plays and tracking data\nmerged_data = pd.merge(plays, tracking_week1, on=['gameId', 'playId'])\n\n# Filter for pre-snap frames\npre_snap_data = merged_data[merged_data['frameType'] == 'BEFORE_SNAP']\n\n# Group by play and calculate pre-snap features\npre_snap_features = pre_snap_data.groupby(['gameId', 'playId']).agg({\n    'x': ['mean', 'std'],\n    'y': ['mean', 'std'],\n    's': ['mean', 'max'],\n    'a': ['mean', 'max'],\n    'o': ['mean', 'std'],\n    'dir': ['mean', 'std']\n}).reset_index()\n\n# Flatten column names\npre_snap_features.columns = ['_'.join(col).strip() for col in pre_snap_features.columns.values]\n\n# Rename columns to avoid conflicts\npre_snap_features = pre_snap_features.rename(columns={\n    'gameId_': 'gameId',\n    'playId_': 'playId'\n})\n\n# Merge pre-snap features with play data\nfinal_data = pd.merge(plays, pre_snap_features, on=['gameId', 'playId'], how='left')\n\nprint(\"Final data shape:\", final_data.shape)\nprint(\"\\nColumns in final_data:\")\nprint(final_data.columns)\nprint(\"\\nFirst few rows of final_data:\")\nprint(final_data.head())\n\n# Check for any missing values in the final dataset\nmissing_values = final_data.isnull().sum()\nprint(\"\\nMissing values in final_data:\")\nprint(missing_values[missing_values > 0])","metadata":{"execution":{"iopub.status.busy":"2024-10-16T20:18:35.234967Z","iopub.execute_input":"2024-10-16T20:18:35.235482Z","iopub.status.idle":"2024-10-16T20:19:16.238318Z","shell.execute_reply.started":"2024-10-16T20:18:35.235439Z","shell.execute_reply":"2024-10-16T20:19:16.236582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Assuming final_data is your current dataframe\n# Fill missing values in categorical columns with 'Unknown'\ncategorical_columns = final_data.select_dtypes(include=['object']).columns\nfinal_data[categorical_columns] = final_data[categorical_columns].fillna('Unknown')\n\n# Fill missing values in numerical columns with the mean of that column\nnumerical_columns = final_data.select_dtypes(include=['float64', 'int64']).columns\nfinal_data[numerical_columns] = final_data[numerical_columns].fillna(final_data[numerical_columns].mean())\n\n# Create a new feature to indicate whether a play is a pass or run\nfinal_data['is_pass_play'] = final_data['passResult'].apply(lambda x: 1 if x != 'Unknown' else 0)\n\n# Print summary of the updated dataset\nprint(\"Updated dataset shape:\", final_data.shape)\nprint(\"\\nMissing values after preprocessing:\")\nprint(final_data.isnull().sum().sum())\nprint(\"\\nSample of the updated dataset:\")\nprint(final_data.head())\nprint(\"\\nDistribution of pass vs. run plays:\")\nprint(final_data['is_pass_play'].value_counts(normalize=True))","metadata":{"execution":{"iopub.status.busy":"2024-10-16T20:20:53.124141Z","iopub.execute_input":"2024-10-16T20:20:53.124712Z","iopub.status.idle":"2024-10-16T20:20:53.308122Z","shell.execute_reply.started":"2024-10-16T20:20:53.124664Z","shell.execute_reply":"2024-10-16T20:20:53.306084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.impute import SimpleImputer\n\n# Assuming final_data is your current dataframe\n\n# Select relevant pre-snap features\ncategorical_features = ['offenseFormation']\nnumeric_features = ['quarter', 'down', 'yardsToGo', 'yardlineNumber',\n                    'preSnapHomeTeamWinProbability', 'preSnapVisitorTeamWinProbability',\n                    'x_mean', 'y_mean', 's_mean', 'a_mean', 'o_mean', 'dir_mean']\n\n# Create additional pre-snap features\nfinal_data['time_remaining'] = final_data['quarter'].map({1: 45, 2: 30, 3: 15, 4: 0}) + \\\n                               final_data['gameClock'].apply(lambda x: int(x.split(':')[0]) + int(x.split(':')[1])/60)\nfinal_data['score_differential'] = final_data['preSnapHomeScore'] - final_data['preSnapVisitorScore']\n\nnumeric_features += ['time_remaining', 'score_differential']\n\n# Prepare data for modeling\nX = final_data[categorical_features + numeric_features]\ny = final_data['is_pass_play']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create preprocessing steps\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)\n    ])\n\n# Create a pipeline\nclf = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n])\n\n# Fit the pipeline\nclf.fit(X_train, y_train)\n\n# Make predictions\ny_pred = clf.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Model Accuracy:\", accuracy)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n\n# Feature importance\nfeature_names = (numeric_features + \n                 clf.named_steps['preprocessor']\n                 .named_transformers_['cat']\n                 .named_steps['onehot']\n                 .get_feature_names_out(categorical_features).tolist())\n\nfeature_importance = pd.DataFrame({\n    'feature': feature_names,\n    'importance': clf.named_steps['classifier'].feature_importances_\n}).sort_values('importance', ascending=False)\n\nprint(\"\\nTop 10 Most Important Features:\")\nprint(feature_importance.head(10))","metadata":{"execution":{"iopub.status.busy":"2024-10-16T20:30:07.561959Z","iopub.execute_input":"2024-10-16T20:30:07.562672Z","iopub.status.idle":"2024-10-16T20:30:10.792207Z","shell.execute_reply.started":"2024-10-16T20:30:07.562627Z","shell.execute_reply":"2024-10-16T20:30:10.790927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_val_score, RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n# Assuming you have X and y from your previous code\n\n# 1. Visualize feature importances\nplt.figure(figsize=(10, 6))\nfeature_importance.plot(x='feature', y='importance', kind='bar')\nplt.title('Feature Importances')\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()\n\n# 2. Perform cross-validation\ncv_scores = cross_val_score(clf, X, y, cv=5)\nprint(f\"Cross-validation scores: {cv_scores}\")\nprint(f\"Mean CV score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n\n# 3. Hyperparameter tuning\nparam_dist = {\n    'classifier__n_estimators': [100, 200, 300],\n    'classifier__max_depth': [None, 10, 20, 30],\n    'classifier__min_samples_split': [2, 5, 10],\n    'classifier__min_samples_leaf': [1, 2, 4]\n}\n\nrandom_search = RandomizedSearchCV(clf, param_distributions=param_dist, \n                                   n_iter=20, cv=5, random_state=42, n_jobs=-1)\nrandom_search.fit(X, y)\n\nprint(\"Best parameters:\", random_search.best_params_)\nprint(\"Best cross-validation score:\", random_search.best_score_)\n\n# Train the best model\nbest_model = random_search.best_estimator_\nbest_model.fit(X, y)\n\n# Get feature importances from the best model\nfeature_names = (numeric_features + \n                 best_model.named_steps['preprocessor']\n                 .named_transformers_['cat']\n                 .named_steps['onehot']\n                 .get_feature_names_out(categorical_features).tolist())\n\nfeature_importance = pd.DataFrame({\n    'feature': feature_names,\n    'importance': best_model.named_steps['classifier'].feature_importances_\n}).sort_values('importance', ascending=False)\n\nprint(\"\\nTop 10 Most Important Features (Best Model):\")\nprint(feature_importance.head(10))","metadata":{"execution":{"iopub.status.busy":"2024-10-16T20:32:27.960775Z","iopub.execute_input":"2024-10-16T20:32:27.961367Z","iopub.status.idle":"2024-10-16T20:36:04.067946Z","shell.execute_reply.started":"2024-10-16T20:32:27.961318Z","shell.execute_reply":"2024-10-16T20:36:04.066069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\nfrom sklearn.model_selection import train_test_split\n\n# Assuming best_model is your trained model from the previous step\n\n# 1. Visualize feature importances\nplt.figure(figsize=(12, 6))\nfeature_importance.plot(x='feature', y='importance', kind='bar')\nplt.title('Feature Importances')\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()\n\n# 2. Create confusion matrix\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\ny_pred = best_model.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n\n# 3. Plot ROC curve\ny_pred_proba = best_model.predict_proba(X_test)[:, 1]\nfpr, tpr, _ = roc_curve(y_test, y_pred_proba)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n# Print classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-10-16T20:48:53.420173Z","iopub.execute_input":"2024-10-16T20:48:53.421826Z","iopub.status.idle":"2024-10-16T20:48:55.076592Z","shell.execute_reply.started":"2024-10-16T20:48:53.421764Z","shell.execute_reply":"2024-10-16T20:48:55.075024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Assuming 'best_model' is your trained model and 'X' is your feature dataset\n\n# 1. Feature Importance Plot\nfeature_importance = best_model.named_steps['classifier'].feature_importances_\nfeature_names = best_model.named_steps['preprocessor'].get_feature_names_out()\n\n# Sort features by importance\nsorted_idx = feature_importance.argsort()\nsorted_features = feature_names[sorted_idx]\nsorted_importance = feature_importance[sorted_idx]\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x=sorted_importance[-15:], y=sorted_features[-15:], orient='h')  # Show top 15 features\nplt.title('Top 15 Feature Importance')\nplt.xlabel('Importance')\nplt.tight_layout()\nplt.show()\n\n# 2. Confusion Matrix\ny_pred = best_model.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()\n\n# Print classification report\nprint(classification_report(y_test, y_pred))\n\n# Print top 10 most important features\nprint(\"\\nTop 10 Most Important Features:\")\nfor feature, importance in zip(sorted_features[-10:], sorted_importance[-10:]):\n    print(f\"{feature}: {importance:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-16T20:56:48.177258Z","iopub.execute_input":"2024-10-16T20:56:48.177832Z","iopub.status.idle":"2024-10-16T20:56:49.449166Z","shell.execute_reply.started":"2024-10-16T20:56:48.177782Z","shell.execute_reply":"2024-10-16T20:56:49.447937Z"},"trusted":true},"execution_count":null,"outputs":[]}]}